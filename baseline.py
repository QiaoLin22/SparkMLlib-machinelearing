# -*- coding: utf-8 -*-
"""baseline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/155WIM2b44G1jPyJ9CFQ8c1zxXp-zC_5T
"""

#Setting up Colab Spark env
!apt-get update
!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz
!tar xf spark-3.1.1-bin-hadoop2.7.tgz
!pip install -q findspark

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.1.1-bin-hadoop2.7"

import findspark
findspark.init()
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[*]").getOrCreate()

from google.colab import files
files.upload()

# spark.stop()
!pip install pyspark

data = spark.read.csv('YearPredictionMSD.csv', header=False, inferSchema=True)

#DATA Preprocess before Feature extraction and Training
data = data.dropna(how='any')
data = data.dropna(how='all')

feature_cols = data.columns[1:13] 
print(feature_cols)
from pyspark.ml.feature import VectorAssembler
vect_assembler = VectorAssembler(inputCols=feature_cols,outputCol="features")

data_w_features = vect_assembler.transform(data)

data_w_features = data_w_features.withColumnRenamed("_c0", "label")

finalized_data = data_w_features.select("features","label")

from pyspark.ml.feature import StandardScaler

scaler = StandardScaler(inputCol="features", outputCol="scaledFeatures",
                        withStd=True, withMean=False)

# Compute summary statistics by fitting the StandardScaler
scalerModel = scaler.fit(finalized_data)

# Normalize each feature to have unit standard deviation.
scaledData = scalerModel.transform(finalized_data)
scaledData = scaledData.select("scaledFeatures","label")

#Split the data into training and test model with 70% obs. going in training and 30% in testing
train_dataset, test_dataset = scaledData.randomSplit([0.7, 0.3], seed = 12345)

#Multiple Linear Regression
from pyspark.ml.regression import LinearRegression
lr = LinearRegression(featuresCol="scaledFeatures", labelCol="label")

#Train the model on the training using fit() method.
from pyspark.ml.tuning import CrossValidator, ParamGridBuilder
from pyspark.ml.evaluation import RegressionEvaluator

paramGrid = (ParamGridBuilder()
             .addGrid(lr.regParam, [0.01, 0.1, 0.5])
             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])
             .addGrid(lr.maxIter, [10, 100])
             .build())

# In this case the estimator is simply the linear regression.
# A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.
lrevaluator = RegressionEvaluator(predictionCol="prediction", labelCol="label", metricName="r2")
lrcv = CrossValidator(estimator=lr,
                           estimatorParamMaps=paramGrid,
                           evaluator = lrevaluator,
                           numFolds=2)
# Run cross validations
lrcvModel = lrcv.fit(train_dataset)
print(lrcvModel)

# Get Model Summary Statistics
lrcvSummary = lrcvModel.bestModel.summary
print("Coefficient Standard Errors: " + str(lrcvSummary.coefficientStandardErrors))

# Use test set here so we can measure the accuracy of our model on new data
lrpredictions = lrcvModel.transform(test_dataset)

# cvModel uses the best model found from the Cross Validation
# Evaluate best model
print('r2:', lrevaluator.evaluate(lrpredictions))

# lrpredictions.show()
import matplotlib.pyplot as plt
import seaborn as sns
# dtlrpredictions.show()
prediction = [lrpredictions.select('prediction').collect()]
label = [lrpredictions.select('label').collect()]

fig = plt.figure(figsize=(15,5))
ax = fig.add_subplot(111)

sns.distplot(prediction, kde=True, ax = ax, hist=False, bins = 10)
sns.distplot(label, kde=True, ax = ax, hist=False, bins = 10)

plt.show()

#Decision Tree Linear Regression
from pyspark.ml.regression import DecisionTreeRegressor
from pyspark.ml.evaluation import RegressionEvaluator

dtlr = DecisionTreeRegressor(featuresCol="scaledFeatures", labelCol="label")

#Train the model on the training using fit() method.
from pyspark.ml.tuning import CrossValidator, ParamGridBuilder
from pyspark.ml.evaluation import RegressionEvaluator

dtparamGrid = (ParamGridBuilder()
             .addGrid(dtlr.maxDepth, [2, 5])
             .addGrid(dtlr.maxBins, [10, 20])
             .build())

# In this case the estimator is decision tree linear regression.
dtlrevaluator = RegressionEvaluator(predictionCol="prediction", labelCol="label", metricName="r2")
dtlrcv = CrossValidator(estimator=dtlr,
                           estimatorParamMaps=dtparamGrid,
                           evaluator = dtlrevaluator,
                           numFolds=2)
# Run cross validations
dtlrcvModel = dtlrcv.fit(train_dataset)
print(dtlrcvModel)

# Use test set here so we can measure the accuracy of our model on new data
dtlrpredictions = dtlrcvModel.transform(test_dataset)

# cvModel uses the best model found from the Cross Validation
# Evaluate best model
print('r2:', dtlrevaluator.evaluate(dtlrpredictions))

import matplotlib.pyplot as plt
import seaborn as sns
# dtlrpredictions.show()
prediction = [dtlrpredictions.select('prediction').collect()]
label = [dtlrpredictions.select('label').collect()]

fig = plt.figure(figsize=(15,5))
ax = fig.add_subplot(111)

sns.distplot(prediction, kde=True, ax = ax, hist=False, bins = 10)
sns.distplot(label, kde=True, ax = ax, hist=False, bins = 10)

plt.show()

#Random Forest Regression
from pyspark.ml.regression import RandomForestRegressor
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator
from pyspark.ml.evaluation import RegressionEvaluator
rflr = RandomForestRegressor(labelCol="label", featuresCol="scaledFeatures")

rfparamGrid = (ParamGridBuilder()
               .addGrid(rflr.maxDepth, [2, 5])
               .addGrid(rflr.maxBins, [5, 10])
               .addGrid(rflr.numTrees, [5, 20])
             .build())

# In this case the estimator is random forest regression.
rflrevaluator = RegressionEvaluator(predictionCol="prediction", labelCol="label", metricName="r2")
rflrcv = CrossValidator(estimator = rflr,
                      estimatorParamMaps = rfparamGrid,
                      evaluator = rfevaluator,
                      numFolds = 2)
# Run cross validations
rflrcvModel = rflrcv.fit(train_dataset)
print(rflrcvModel)

# Use test set here so we can measure the accuracy of our model on new data
rflrpredictions = rflrcvModel.transform(test_dataset)

# cvModel uses the best model found from the Cross Validation
# Evaluate best model
print('r2:', rflrevaluator.evaluate(rflrpredictions))

import matplotlib.pyplot as plt
import seaborn as sns
# rflrpredictions.show()
prediction = [rflrpredictions.select('prediction').collect()]
label = [rflrpredictions.select('label').collect()]

fig = plt.figure(figsize=(15,5))
ax = fig.add_subplot(111)

sns.distplot(prediction, kde=True, ax = ax, hist=False, bins = 10)
sns.distplot(label, kde=True, ax = ax, hist=False, bins = 10)

plt.show()

#Polynomial Regression
from pyspark.ml.regression import GBTRegressor
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator
from pyspark.ml.evaluation import RegressionEvaluator
gbtlr = GBTRegressor(labelCol="label",featuresCol="scaledFeatures")

gbtparamGrid = (ParamGridBuilder()
  .addGrid(gbtlr.maxDepth, [2, 5])
  .addGrid(gbtlr.maxIter, [10, 100])
  .build())

# In this case the estimator is gradient boost tree regression.
gbtlrevaluator = RegressionEvaluator(predictionCol="prediction", labelCol="label", metricName="r2")
gbtlrcv = CrossValidator(estimator = gbtlr,
                      estimatorParamMaps = gbtparamGrid,
                      evaluator = gbtlrevaluator,
                      numFolds = 2)
# Run cross validations
gbtlrcvModel = gbtlrcv.fit(train_dataset)
print(gbtlrcvModel)

# Use test set here so we can measure the accuracy of our model on new data
gbtlrpredictions = gbtlrcvModel.transform(test_dataset)

# cvModel uses the best model found from the Cross Validation
# Evaluate best model
print('r2:', gbtlrevaluator.evaluate(gbtlrpredictions))

import matplotlib.pyplot as plt
import seaborn as sns
# gbtlrpredictions.show()
prediction = [gbtlrpredictions.select('prediction').collect()]
label = [gbtlrpredictions.select('label').collect()]

fig = plt.figure(figsize=(15,5))
ax = fig.add_subplot(111)

sns.distplot(prediction, kde=True, ax = ax, hist=False, bins = 10)
sns.distplot(label, kde=True, ax = ax, hist=False, bins = 10)

plt.show()